{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "308d1824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF text is: [Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2015-05-19T00:48:02+00:00', 'author': 'Olaf Ronneberger (ronneber@informatik.uni-freiburg.de), Philipp Fischer, Thomas Brox', 'keywords': '', 'moddate': '2015-05-19T00:48:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': 'U-Net: Convolutional Networks for Biomedical Image Segmentation', 'trapped': '/False', 'source': 'Unet for Biomedical Segmentation.pdf', 'total_pages': 8, 'page': 0, 'page_label': '1'}, page_content='U-Net: Convolutional Networks for Biomedical\\nImage Segmentation\\nOlaf Ronneberger, Philipp Fischer, and Thomas Brox\\nComputer Science Department and BIOSS Centre for Biological Signalling Studies,\\nUniversity of Freiburg, Germany\\nronneber@informatik.uni-freiburg.de,\\nWWW home page: http://lmb.informatik.uni-freiburg.de/\\nAbstract. There is large consent that successful training of deep net-\\nworks requires many thousand annotated training samples. In this pa-\\nper, we present a network and training strategy that relies on the strong\\nuse of data augmentation to use the available annotated samples more\\neﬃciently. The architecture consists of a contracting path to capture\\ncontext and a symmetric expanding path that enables precise localiza-\\ntion. We show that such a network can be trained end-to-end from very\\nfew images and outperforms the prior best method (a sliding-window\\nconvolutional network) on the ISBI challenge for segmentation of neu-\\nronal structures in electron microscopic stacks. Using the same net-\\nwork trained on transmitted light microscopy images (phase contrast\\nand DIC) we won the ISBI cell tracking challenge 2015 in these cate-\\ngories by a large margin. Moreover, the network is fast. Segmentation\\nof a 512x512 image takes less than a second on a recent GPU. The full\\nimplementation (based on Caﬀe) and the trained networks are available\\nat http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.\\n1 Introduction\\nIn the last two years, deep convolutional networks have outperformed the state of\\nthe art in many visual recognition tasks, e.g. [7,3]. While convolutional networks\\nhave already existed for a long time [8], their success was limited due to the\\nsize of the available training sets and the size of the considered networks. The\\nbreakthrough by Krizhevsky et al. [7] was due to supervised training of a large\\nnetwork with 8 layers and millions of parameters on the ImageNet dataset with\\n1 million training images. Since then, even larger and deeper networks have been\\ntrained [12].\\nThe typical use of convolutional networks is on classiﬁcation tasks, where\\nthe output to an image is a single class label. However, in many visual tasks,\\nespecially in biomedical image processing, the desired output should include\\nlocalization, i.e., a class label is supposed to be assigned to each pixel. More-\\nover, thousands of training images are usually beyond reach in biomedical tasks.\\nHence, Ciresan et al. [1] trained a network in a sliding-window setup to predict\\nthe class label of each pixel by providing a local region (patch) around that pixel\\narXiv:1505.04597v1  [cs.CV]  18 May 2015'), Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2015-05-19T00:48:02+00:00', 'author': 'Olaf Ronneberger (ronneber@informatik.uni-freiburg.de), Philipp Fischer, Thomas Brox', 'keywords': '', 'moddate': '2015-05-19T00:48:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': 'U-Net: Convolutional Networks for Biomedical Image Segmentation', 'trapped': '/False', 'source': 'Unet for Biomedical Segmentation.pdf', 'total_pages': 8, 'page': 1, 'page_label': '2'}, page_content='2\\ncopy and crop\\ninput\\nimage\\ntile\\noutput \\nsegmentation \\nmap\\n641\\n128\\n256\\n512\\n1024\\nmax pool 2x2\\nup-conv 2x2\\nconv 3x3, ReLU\\n572 x 572\\n284²\\n64\\n128\\n256\\n512\\n570 x 570\\n568 x 568\\n282²\\n280²140²\\n138²\\n136²68²\\n66²\\n64²32²\\n28²\\n56²\\n54²\\n52²\\n512\\n104²\\n102²\\n100² 200²\\n30²\\n198²\\n196² 392 x 392\\n390 x 390\\n388 x 388\\n388 x 388\\n1024\\n512 256\\n256 128\\n64128 64 2\\nconv 1x1\\nFig. 1.U-net architecture (example for 32x32 pixels in the lowest resolution). Each blue\\nbox corresponds to a multi-channel feature map. The number of channels is denoted\\non top of the box. The x-y-size is provided at the lower left edge of the box. White\\nboxes represent copied feature maps. The arrows denote the diﬀerent operations.\\nas input. First, this network can localize. Secondly, the training data in terms\\nof patches is much larger than the number of training images. The resulting\\nnetwork won the EM segmentation challenge at ISBI 2012 by a large margin.\\nObviously, the strategy in Ciresan et al. [1] has two drawbacks. First, it\\nis quite slow because the network must be run separately for each patch, and\\nthere is a lot of redundancy due to overlapping patches. Secondly, there is a\\ntrade-oﬀ between localization accuracy and the use of context. Larger patches\\nrequire more max-pooling layers that reduce the localization accuracy, while\\nsmall patches allow the network to see only little context. More recent approaches\\n[11,4] proposed a classiﬁer output that takes into account the features from\\nmultiple layers. Good localization and the use of context are possible at the\\nsame time.\\nIn this paper, we build upon a more elegant architecture, the so-called “fully\\nconvolutional network” [9]. We modify and extend this architecture such that it\\nworks with very few training images and yields more precise segmentations; see\\nFigure 1. The main idea in [9] is to supplement a usual contracting network by\\nsuccessive layers, where pooling operators are replaced by upsampling operators.\\nHence, these layers increase the resolution of the output. In order to localize, high\\nresolution features from the contracting path are combined with the upsampled'), Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2015-05-19T00:48:02+00:00', 'author': 'Olaf Ronneberger (ronneber@informatik.uni-freiburg.de), Philipp Fischer, Thomas Brox', 'keywords': '', 'moddate': '2015-05-19T00:48:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': 'U-Net: Convolutional Networks for Biomedical Image Segmentation', 'trapped': '/False', 'source': 'Unet for Biomedical Segmentation.pdf', 'total_pages': 8, 'page': 2, 'page_label': '3'}, page_content='3\\nFig. 2.Overlap-tile strategy for seamless segmentation of arbitrary large images (here\\nsegmentation of neuronal structures in EM stacks). Prediction of the segmentation in\\nthe yellow area, requires image data within the blue area as input. Missing input data\\nis extrapolated by mirroring\\noutput. A successive convolution layer can then learn to assemble a more precise\\noutput based on this information.\\nOne important modiﬁcation in our architecture is that in the upsampling\\npart we have also a large number of feature channels, which allow the network\\nto propagate context information to higher resolution layers. As a consequence,\\nthe expansive path is more or less symmetric to the contracting path, and yields\\na u-shaped architecture. The network does not have any fully connected layers\\nand only uses the valid part of each convolution, i.e., the segmentation map only\\ncontains the pixels, for which the full context is available in the input image.\\nThis strategy allows the seamless segmentation of arbitrarily large images by an\\noverlap-tile strategy (see Figure 2). To predict the pixels in the border region\\nof the image, the missing context is extrapolated by mirroring the input image.\\nThis tiling strategy is important to apply the network to large images, since\\notherwise the resolution would be limited by the GPU memory.\\nAs for our tasks there is very little training data available, we use excessive\\ndata augmentation by applying elastic deformations to the available training im-\\nages. This allows the network to learn invariance to such deformations, without\\nthe need to see these transformations in the annotated image corpus. This is\\nparticularly important in biomedical segmentation, since deformation used to\\nbe the most common variation in tissue and realistic deformations can be simu-\\nlated eﬃciently. The value of data augmentation for learning invariance has been\\nshown in Dosovitskiy et al. [2] in the scope of unsupervised feature learning.\\nAnother challenge in many cell segmentation tasks is the separation of touch-\\ning objects of the same class; see Figure 3. To this end, we propose the use of\\na weighted loss, where the separating background labels between touching cells\\nobtain a large weight in the loss function.\\nThe resulting network is applicable to various biomedical segmentation prob-\\nlems. In this paper, we show results on the segmentation of neuronal structures\\nin EM stacks (an ongoing competition started at ISBI 2012), where we out-'), Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2015-05-19T00:48:02+00:00', 'author': 'Olaf Ronneberger (ronneber@informatik.uni-freiburg.de), Philipp Fischer, Thomas Brox', 'keywords': '', 'moddate': '2015-05-19T00:48:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': 'U-Net: Convolutional Networks for Biomedical Image Segmentation', 'trapped': '/False', 'source': 'Unet for Biomedical Segmentation.pdf', 'total_pages': 8, 'page': 3, 'page_label': '4'}, page_content='4\\nperformed the network of Ciresan et al. [1]. Furthermore, we show results for\\ncell segmentation in light microscopy images from the ISBI cell tracking chal-\\nlenge 2015. Here we won with a large margin on the two most challenging 2D\\ntransmitted light datasets.\\n2 Network Architecture\\nThe network architecture is illustrated in Figure 1. It consists of a contracting\\npath (left side) and an expansive path (right side). The contracting path follows\\nthe typical architecture of a convolutional network. It consists of the repeated\\napplication of two 3x3 convolutions (unpadded convolutions), each followed by\\na rectiﬁed linear unit (ReLU) and a 2x2 max pooling operation with stride 2\\nfor downsampling. At each downsampling step we double the number of feature\\nchannels. Every step in the expansive path consists of an upsampling of the\\nfeature map followed by a 2x2 convolution (“up-convolution”) that halves the\\nnumber of feature channels, a concatenation with the correspondingly cropped\\nfeature map from the contracting path, and two 3x3 convolutions, each fol-\\nlowed by a ReLU. The cropping is necessary due to the loss of border pixels in\\nevery convolution. At the ﬁnal layer a 1x1 convolution is used to map each 64-\\ncomponent feature vector to the desired number of classes. In total the network\\nhas 23 convolutional layers.\\nTo allow a seamless tiling of the output segmentation map (see Figure 2), it\\nis important to select the input tile size such that all 2x2 max-pooling operations\\nare applied to a layer with an even x- and y-size.\\n3 Training\\nThe input images and their corresponding segmentation maps are used to train\\nthe network with the stochastic gradient descent implementation of Caﬀe [6].\\nDue to the unpadded convolutions, the output image is smaller than the input\\nby a constant border width. To minimize the overhead and make maximum use\\nof the GPU memory, we favor large input tiles over a large batch size and hence\\nreduce the batch to a single image. Accordingly we use a high momentum (0.99)\\nsuch that a large number of the previously seen training samples determine the\\nupdate in the current optimization step.\\nThe energy function is computed by a pixel-wise soft-max over the ﬁnal\\nfeature map combined with the cross entropy loss function. The soft-max is\\ndeﬁned as pk(x) = exp( ak(x))/\\n(∑K\\nk′=1 exp(ak′ (x))\\n)\\nwhere ak(x) denotes the\\nactivation in feature channel k at the pixel position x ∈Ω with Ω ⊂Z2. K\\nis the number of classes and pk(x) is the approximated maximum-function. I.e.\\npk(x) ≈1 for the k that has the maximum activation ak(x) and pk(x) ≈0 for\\nall other k. The cross entropy then penalizes at each position the deviation of\\npℓ(x)(x) from 1 using\\nE =\\n∑\\nx∈Ω\\nw(x) log(pℓ(x)(x)) (1)'), Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2015-05-19T00:48:02+00:00', 'author': 'Olaf Ronneberger (ronneber@informatik.uni-freiburg.de), Philipp Fischer, Thomas Brox', 'keywords': '', 'moddate': '2015-05-19T00:48:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': 'U-Net: Convolutional Networks for Biomedical Image Segmentation', 'trapped': '/False', 'source': 'Unet for Biomedical Segmentation.pdf', 'total_pages': 8, 'page': 4, 'page_label': '5'}, page_content='5\\na\\n b\\n c\\n d\\nFig. 3.HeLa cells on glass recorded with DIC (diﬀerential interference contrast) mi-\\ncroscopy. (a) raw image. ( b) overlay with ground truth segmentation. Diﬀerent colors\\nindicate diﬀerent instances of the HeLa cells. (c) generated segmentation mask (white:\\nforeground, black: background). ( d) map with a pixel-wise loss weight to force the\\nnetwork to learn the border pixels.\\nwhere ℓ : Ω →{1,...,K }is the true label of each pixel and w : Ω →R is\\na weight map that we introduced to give some pixels more importance in the\\ntraining.\\nWe pre-compute the weight map for each ground truth segmentation to com-\\npensate the diﬀerent frequency of pixels from a certain class in the training\\ndata set, and to force the network to learn the small separation borders that we\\nintroduce between touching cells (See Figure 3c and d).\\nThe separation border is computed using morphological operations. The\\nweight map is then computed as\\nw(x) = wc(x) + w0 ·exp\\n(\\n−(d1(x) + d2(x))2\\n2σ2\\n)\\n(2)\\nwhere wc : Ω →R is the weight map to balance the class frequencies,d1 : Ω →R\\ndenotes the distance to the border of the nearest cell andd2 : Ω →R the distance\\nto the border of the second nearest cell. In our experiments we set w0 = 10 and\\nσ≈5 pixels.\\nIn deep networks with many convolutional layers and diﬀerent paths through\\nthe network, a good initialization of the weights is extremely important. Oth-\\nerwise, parts of the network might give excessive activations, while other parts\\nnever contribute. Ideally the initial weights should be adapted such that each\\nfeature map in the network has approximately unit variance. For a network with\\nour architecture (alternating convolution and ReLU layers) this can be achieved\\nby drawing the initial weights from a Gaussian distribution with a standard\\ndeviation of\\n√\\n2/N, where N denotes the number of incoming nodes of one neu-\\nron [5]. E.g. for a 3x3 convolution and 64 feature channels in the previous layer\\nN = 9 ·64 = 576.\\n3.1 Data Augmentation\\nData augmentation is essential to teach the network the desired invariance and\\nrobustness properties, when only few training samples are available. In case of'), Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2015-05-19T00:48:02+00:00', 'author': 'Olaf Ronneberger (ronneber@informatik.uni-freiburg.de), Philipp Fischer, Thomas Brox', 'keywords': '', 'moddate': '2015-05-19T00:48:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': 'U-Net: Convolutional Networks for Biomedical Image Segmentation', 'trapped': '/False', 'source': 'Unet for Biomedical Segmentation.pdf', 'total_pages': 8, 'page': 5, 'page_label': '6'}, page_content='6\\nmicroscopical images we primarily need shift and rotation invariance as well as\\nrobustness to deformations and gray value variations. Especially random elas-\\ntic deformations of the training samples seem to be the key concept to train\\na segmentation network with very few annotated images. We generate smooth\\ndeformations using random displacement vectors on a coarse 3 by 3 grid. The\\ndisplacements are sampled from a Gaussian distribution with 10 pixels standard\\ndeviation. Per-pixel displacements are then computed using bicubic interpola-\\ntion. Drop-out layers at the end of the contracting path perform further implicit\\ndata augmentation.\\n4 Experiments\\nWe demonstrate the application of the u-net to three diﬀerent segmentation\\ntasks. The ﬁrst task is the segmentation of neuronal structures in electron mi-\\ncroscopic recordings. An example of the data set and our obtained segmentation\\nis displayed in Figure 2. We provide the full result as Supplementary Material.\\nThe data set is provided by the EM segmentation challenge [14] that was started\\nat ISBI 2012 and is still open for new contributions. The training data is a set of\\n30 images (512x512 pixels) from serial section transmission electron microscopy\\nof the Drosophila ﬁrst instar larva ventral nerve cord (VNC). Each image comes\\nwith a corresponding fully annotated ground truth segmentation map for cells\\n(white) and membranes (black). The test set is publicly available, but its seg-\\nmentation maps are kept secret. An evaluation can be obtained by sending the\\npredicted membrane probability map to the organizers. The evaluation is done\\nby thresholding the map at 10 diﬀerent levels and computation of the “warping\\nerror”, the “Rand error” and the “pixel error” [14].\\nThe u-net (averaged over 7 rotated versions of the input data) achieves with-\\nout any further pre- or postprocessing a warping error of 0.0003529 (the new\\nbest score, see Table 1) and a rand-error of 0.0382.\\nThis is signiﬁcantly better than the sliding-window convolutional network\\nresult by Ciresan et al. [1], whose best submission had a warping error of 0.000420\\nand a rand error of 0.0504. In terms of rand error the only better performing\\nTable 1.Ranking on the EM segmentation challenge [14] (march 6th, 2015), sorted\\nby warping error.\\nRank Group name Warping Error Rand Error Pixel Error\\n** human values ** 0.000005 0.0021 0.0010\\n1. u-net 0.000353 0.0382 0.0611\\n2. DIVE-SCI 0.000355 0.0305 0.0584\\n3. IDSIA [1] 0.000420 0.0504 0.0613\\n4. DIVE 0.000430 0.0545 0.0582\\n...\\n10. IDSIA-SCI 0.000653 0.0189 0.1027'), Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2015-05-19T00:48:02+00:00', 'author': 'Olaf Ronneberger (ronneber@informatik.uni-freiburg.de), Philipp Fischer, Thomas Brox', 'keywords': '', 'moddate': '2015-05-19T00:48:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': 'U-Net: Convolutional Networks for Biomedical Image Segmentation', 'trapped': '/False', 'source': 'Unet for Biomedical Segmentation.pdf', 'total_pages': 8, 'page': 6, 'page_label': '7'}, page_content='7\\na\\n b\\n c\\n d\\nFig. 4.Result on the ISBI cell tracking challenge. ( a) part of an input image of the\\n“PhC-U373” data set. (b) Segmentation result (cyan mask) with manual ground truth\\n(yellow border) (c) input image of the “DIC-HeLa” data set. ( d) Segmentation result\\n(random colored masks) with manual ground truth (yellow border).\\nTable 2.Segmentation results (IOU) on the ISBI cell tracking challenge 2015.\\nName PhC-U373 DIC-HeLa\\nIMCB-SG (2014) 0.2669 0.2935\\nKTH-SE (2014) 0.7953 0.4607\\nHOUS-US (2014) 0.5323 -\\nsecond-best 2015 0.83 0.46\\nu-net (2015) 0.9203 0.7756\\nalgorithms on this data set use highly data set speciﬁc post-processing methods1\\napplied to the probability map of Ciresan et al. [1].\\nWe also applied the u-net to a cell segmentation task in light microscopic im-\\nages. This segmenation task is part of the ISBI cell tracking challenge 2014 and\\n2015 [10,13]. The ﬁrst data set “PhC-U373”2 contains Glioblastoma-astrocytoma\\nU373 cells on a polyacrylimide substrate recorded by phase contrast microscopy\\n(see Figure 4a,b and Supp. Material). It contains 35 partially annotated train-\\ning images. Here we achieve an average IOU (“intersection over union”) of 92%,\\nwhich is signiﬁcantly better than the second best algorithm with 83% (see Ta-\\nble 2). The second data set “DIC-HeLa” 3 are HeLa cells on a ﬂat glass recorded\\nby diﬀerential interference contrast (DIC) microscopy (see Figure 3, Figure 4c,d\\nand Supp. Material). It contains 20 partially annotated training images. Here we\\nachieve an average IOU of 77.5% which is signiﬁcantly better than the second\\nbest algorithm with 46%.\\n5 Conclusion\\nThe u-net architecture achieves very good performance on very diﬀerent biomed-\\nical segmentation applications. Thanks to data augmentation with elastic defor-\\n1 The authors of this algorithm have submitted 78 diﬀerent solutions to achieve this\\nresult.\\n2 Data set provided by Dr. Sanjay Kumar. Department of Bioengineering University\\nof California at Berkeley. Berkeley CA (USA)\\n3 Data set provided by Dr. Gert van Cappellen Erasmus Medical Center. Rotterdam.\\nThe Netherlands'), Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2015-05-19T00:48:02+00:00', 'author': 'Olaf Ronneberger (ronneber@informatik.uni-freiburg.de), Philipp Fischer, Thomas Brox', 'keywords': '', 'moddate': '2015-05-19T00:48:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': 'U-Net: Convolutional Networks for Biomedical Image Segmentation', 'trapped': '/False', 'source': 'Unet for Biomedical Segmentation.pdf', 'total_pages': 8, 'page': 7, 'page_label': '8'}, page_content='8\\nmations, it only needs very few annotated images and has a very reasonable\\ntraining time of only 10 hours on a NVidia Titan GPU (6 GB). We provide the\\nfull Caﬀe[6]-based implementation and the trained networks 4. We are sure that\\nthe u-net architecture can be applied easily to many more tasks.\\nAcknowlegements\\nThis study was supported by the Excellence Initiative of the German Federal\\nand State governments (EXC 294) and by the BMBF (Fkz 0316185B).\\nReferences\\n1. Ciresan, D.C., Gambardella, L.M., Giusti, A., Schmidhuber, J.: Deep neural net-\\nworks segment neuronal membranes in electron microscopy images. In: NIPS. pp.\\n2852–2860 (2012)\\n2. Dosovitskiy, A., Springenberg, J.T., Riedmiller, M., Brox, T.: Discriminative un-\\nsupervised feature learning with convolutional neural networks. In: NIPS (2014)\\n3. Girshick, R., Donahue, J., Darrell, T., Malik, J.: Rich feature hierarchies for ac-\\ncurate object detection and semantic segmentation. In: Proceedings of the IEEE\\nConference on Computer Vision and Pattern Recognition (CVPR) (2014)\\n4. Hariharan, B., Arbelez, P., Girshick, R., Malik, J.: Hypercolumns for object seg-\\nmentation and ﬁne-grained localization (2014), arXiv:1411.5752 [cs.CV]\\n5. He, K., Zhang, X., Ren, S., Sun, J.: Delving deep into rectiﬁers: Surpassing human-\\nlevel performance on imagenet classiﬁcation (2015), arXiv:1502.01852 [cs.CV]\\n6. Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadar-\\nrama, S., Darrell, T.: Caﬀe: Convolutional architecture for fast feature embedding\\n(2014), arXiv:1408.5093 [cs.CV]\\n7. Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classiﬁcation with deep con-\\nvolutional neural networks. In: NIPS. pp. 1106–1114 (2012)\\n8. LeCun, Y., Boser, B., Denker, J.S., Henderson, D., Howard, R.E., Hubbard, W.,\\nJackel, L.D.: Backpropagation applied to handwritten zip code recognition. Neural\\nComputation 1(4), 541–551 (1989)\\n9. Long, J., Shelhamer, E., Darrell, T.: Fully convolutional networks for semantic\\nsegmentation (2014), arXiv:1411.4038 [cs.CV]\\n10. Maska, M., (...), de Solorzano, C.O.: A benchmark for comparison of cell tracking\\nalgorithms. Bioinformatics 30, 1609–1617 (2014)\\n11. Seyedhosseini, M., Sajjadi, M., Tasdizen, T.: Image segmentation with cascaded\\nhierarchical models and logistic disjunctive normal networks. In: Computer Vision\\n(ICCV), 2013 IEEE International Conference on. pp. 2168–2175 (2013)\\n12. Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale\\nimage recognition (2014), arXiv:1409.1556 [cs.CV]\\n13. WWW: Web page of the cell tracking challenge, http://www.codesolorzano.com/\\ncelltrackingchallenge/Cell_Tracking_Challenge/Welcome.html\\n14. WWW: Web page of the em segmentation challenge, http://brainiac2.mit.edu/\\nisbi_challenge/\\n4 U-net implementation, trained networks and supplementary material available at\\nhttp://lmb.informatik.uni-freiburg.de/people/ronneber/u-net')]\n"
     ]
    }
   ],
   "source": [
    "# Data Ingestion from pdf\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "pdf_loader = PyPDFLoader(\"Unet for Biomedical Segmentation.pdf\")\n",
    "\n",
    "pdf_document = pdf_loader.load()\n",
    "\n",
    "print(f'PDF text is: {pdf_document}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abf53e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2015-05-19T00:48:02+00:00', 'author': 'Olaf Ronneberger (ronneber@informatik.uni-freiburg.de), Philipp Fischer, Thomas Brox', 'keywords': '', 'moddate': '2015-05-19T00:48:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': 'U-Net: Convolutional Networks for Biomedical Image Segmentation', 'trapped': '/False', 'source': 'Unet for Biomedical Segmentation.pdf', 'total_pages': 8, 'page': 0, 'page_label': '1'}, page_content='U-Net: Convolutional Networks for Biomedical\\nImage Segmentation\\nOlaf Ronneberger, Philipp Fischer, and Thomas Brox\\nComputer Science Department and BIOSS Centre for Biological Signalling Studies,\\nUniversity of Freiburg, Germany\\nronneber@informatik.uni-freiburg.de,\\nWWW home page: http://lmb.informatik.uni-freiburg.de/\\nAbstract. There is large consent that successful training of deep net-\\nworks requires many thousand annotated training samples. In this pa-\\nper, we present a network and training strategy that relies on the strong\\nuse of data augmentation to use the available annotated samples more\\neﬃciently. The architecture consists of a contracting path to capture\\ncontext and a symmetric expanding path that enables precise localiza-\\ntion. We show that such a network can be trained end-to-end from very\\nfew images and outperforms the prior best method (a sliding-window\\nconvolutional network) on the ISBI challenge for segmentation of neu-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2015-05-19T00:48:02+00:00', 'author': 'Olaf Ronneberger (ronneber@informatik.uni-freiburg.de), Philipp Fischer, Thomas Brox', 'keywords': '', 'moddate': '2015-05-19T00:48:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': 'U-Net: Convolutional Networks for Biomedical Image Segmentation', 'trapped': '/False', 'source': 'Unet for Biomedical Segmentation.pdf', 'total_pages': 8, 'page': 0, 'page_label': '1'}, page_content='few images and outperforms the prior best method (a sliding-window\\nconvolutional network) on the ISBI challenge for segmentation of neu-\\nronal structures in electron microscopic stacks. Using the same net-\\nwork trained on transmitted light microscopy images (phase contrast\\nand DIC) we won the ISBI cell tracking challenge 2015 in these cate-\\ngories by a large margin. Moreover, the network is fast. Segmentation\\nof a 512x512 image takes less than a second on a recent GPU. The full\\nimplementation (based on Caﬀe) and the trained networks are available\\nat http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.\\n1 Introduction\\nIn the last two years, deep convolutional networks have outperformed the state of\\nthe art in many visual recognition tasks, e.g. [7,3]. While convolutional networks\\nhave already existed for a long time [8], their success was limited due to the\\nsize of the available training sets and the size of the considered networks. The'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2015-05-19T00:48:02+00:00', 'author': 'Olaf Ronneberger (ronneber@informatik.uni-freiburg.de), Philipp Fischer, Thomas Brox', 'keywords': '', 'moddate': '2015-05-19T00:48:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': 'U-Net: Convolutional Networks for Biomedical Image Segmentation', 'trapped': '/False', 'source': 'Unet for Biomedical Segmentation.pdf', 'total_pages': 8, 'page': 0, 'page_label': '1'}, page_content='have already existed for a long time [8], their success was limited due to the\\nsize of the available training sets and the size of the considered networks. The\\nbreakthrough by Krizhevsky et al. [7] was due to supervised training of a large\\nnetwork with 8 layers and millions of parameters on the ImageNet dataset with\\n1 million training images. Since then, even larger and deeper networks have been\\ntrained [12].\\nThe typical use of convolutional networks is on classiﬁcation tasks, where\\nthe output to an image is a single class label. However, in many visual tasks,\\nespecially in biomedical image processing, the desired output should include\\nlocalization, i.e., a class label is supposed to be assigned to each pixel. More-\\nover, thousands of training images are usually beyond reach in biomedical tasks.\\nHence, Ciresan et al. [1] trained a network in a sliding-window setup to predict\\nthe class label of each pixel by providing a local region (patch) around that pixel'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2015-05-19T00:48:02+00:00', 'author': 'Olaf Ronneberger (ronneber@informatik.uni-freiburg.de), Philipp Fischer, Thomas Brox', 'keywords': '', 'moddate': '2015-05-19T00:48:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': 'U-Net: Convolutional Networks for Biomedical Image Segmentation', 'trapped': '/False', 'source': 'Unet for Biomedical Segmentation.pdf', 'total_pages': 8, 'page': 0, 'page_label': '1'}, page_content='Hence, Ciresan et al. [1] trained a network in a sliding-window setup to predict\\nthe class label of each pixel by providing a local region (patch) around that pixel\\narXiv:1505.04597v1  [cs.CV]  18 May 2015'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2015-05-19T00:48:02+00:00', 'author': 'Olaf Ronneberger (ronneber@informatik.uni-freiburg.de), Philipp Fischer, Thomas Brox', 'keywords': '', 'moddate': '2015-05-19T00:48:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': 'U-Net: Convolutional Networks for Biomedical Image Segmentation', 'trapped': '/False', 'source': 'Unet for Biomedical Segmentation.pdf', 'total_pages': 8, 'page': 1, 'page_label': '2'}, page_content='2\\ncopy and crop\\ninput\\nimage\\ntile\\noutput \\nsegmentation \\nmap\\n641\\n128\\n256\\n512\\n1024\\nmax pool 2x2\\nup-conv 2x2\\nconv 3x3, ReLU\\n572 x 572\\n284²\\n64\\n128\\n256\\n512\\n570 x 570\\n568 x 568\\n282²\\n280²140²\\n138²\\n136²68²\\n66²\\n64²32²\\n28²\\n56²\\n54²\\n52²\\n512\\n104²\\n102²\\n100² 200²\\n30²\\n198²\\n196² 392 x 392\\n390 x 390\\n388 x 388\\n388 x 388\\n1024\\n512 256\\n256 128\\n64128 64 2\\nconv 1x1\\nFig. 1.U-net architecture (example for 32x32 pixels in the lowest resolution). Each blue\\nbox corresponds to a multi-channel feature map. The number of channels is denoted\\non top of the box. The x-y-size is provided at the lower left edge of the box. White\\nboxes represent copied feature maps. The arrows denote the diﬀerent operations.\\nas input. First, this network can localize. Secondly, the training data in terms\\nof patches is much larger than the number of training images. The resulting\\nnetwork won the EM segmentation challenge at ISBI 2012 by a large margin.\\nObviously, the strategy in Ciresan et al. [1] has two drawbacks. First, it'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2015-05-19T00:48:02+00:00', 'author': 'Olaf Ronneberger (ronneber@informatik.uni-freiburg.de), Philipp Fischer, Thomas Brox', 'keywords': '', 'moddate': '2015-05-19T00:48:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': 'U-Net: Convolutional Networks for Biomedical Image Segmentation', 'trapped': '/False', 'source': 'Unet for Biomedical Segmentation.pdf', 'total_pages': 8, 'page': 1, 'page_label': '2'}, page_content='network won the EM segmentation challenge at ISBI 2012 by a large margin.\\nObviously, the strategy in Ciresan et al. [1] has two drawbacks. First, it\\nis quite slow because the network must be run separately for each patch, and\\nthere is a lot of redundancy due to overlapping patches. Secondly, there is a\\ntrade-oﬀ between localization accuracy and the use of context. Larger patches\\nrequire more max-pooling layers that reduce the localization accuracy, while\\nsmall patches allow the network to see only little context. More recent approaches\\n[11,4] proposed a classiﬁer output that takes into account the features from\\nmultiple layers. Good localization and the use of context are possible at the\\nsame time.\\nIn this paper, we build upon a more elegant architecture, the so-called “fully\\nconvolutional network” [9]. We modify and extend this architecture such that it\\nworks with very few training images and yields more precise segmentations; see'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2015-05-19T00:48:02+00:00', 'author': 'Olaf Ronneberger (ronneber@informatik.uni-freiburg.de), Philipp Fischer, Thomas Brox', 'keywords': '', 'moddate': '2015-05-19T00:48:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': 'U-Net: Convolutional Networks for Biomedical Image Segmentation', 'trapped': '/False', 'source': 'Unet for Biomedical Segmentation.pdf', 'total_pages': 8, 'page': 1, 'page_label': '2'}, page_content='convolutional network” [9]. We modify and extend this architecture such that it\\nworks with very few training images and yields more precise segmentations; see\\nFigure 1. The main idea in [9] is to supplement a usual contracting network by\\nsuccessive layers, where pooling operators are replaced by upsampling operators.\\nHence, these layers increase the resolution of the output. In order to localize, high\\nresolution features from the contracting path are combined with the upsampled'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2015-05-19T00:48:02+00:00', 'author': 'Olaf Ronneberger (ronneber@informatik.uni-freiburg.de), Philipp Fischer, Thomas Brox', 'keywords': '', 'moddate': '2015-05-19T00:48:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': 'U-Net: Convolutional Networks for Biomedical Image Segmentation', 'trapped': '/False', 'source': 'Unet for Biomedical Segmentation.pdf', 'total_pages': 8, 'page': 2, 'page_label': '3'}, page_content='3\\nFig. 2.Overlap-tile strategy for seamless segmentation of arbitrary large images (here\\nsegmentation of neuronal structures in EM stacks). Prediction of the segmentation in\\nthe yellow area, requires image data within the blue area as input. Missing input data\\nis extrapolated by mirroring\\noutput. A successive convolution layer can then learn to assemble a more precise\\noutput based on this information.\\nOne important modiﬁcation in our architecture is that in the upsampling\\npart we have also a large number of feature channels, which allow the network\\nto propagate context information to higher resolution layers. As a consequence,\\nthe expansive path is more or less symmetric to the contracting path, and yields\\na u-shaped architecture. The network does not have any fully connected layers\\nand only uses the valid part of each convolution, i.e., the segmentation map only\\ncontains the pixels, for which the full context is available in the input image.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2015-05-19T00:48:02+00:00', 'author': 'Olaf Ronneberger (ronneber@informatik.uni-freiburg.de), Philipp Fischer, Thomas Brox', 'keywords': '', 'moddate': '2015-05-19T00:48:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': 'U-Net: Convolutional Networks for Biomedical Image Segmentation', 'trapped': '/False', 'source': 'Unet for Biomedical Segmentation.pdf', 'total_pages': 8, 'page': 2, 'page_label': '3'}, page_content='and only uses the valid part of each convolution, i.e., the segmentation map only\\ncontains the pixels, for which the full context is available in the input image.\\nThis strategy allows the seamless segmentation of arbitrarily large images by an\\noverlap-tile strategy (see Figure 2). To predict the pixels in the border region\\nof the image, the missing context is extrapolated by mirroring the input image.\\nThis tiling strategy is important to apply the network to large images, since\\notherwise the resolution would be limited by the GPU memory.\\nAs for our tasks there is very little training data available, we use excessive\\ndata augmentation by applying elastic deformations to the available training im-\\nages. This allows the network to learn invariance to such deformations, without\\nthe need to see these transformations in the annotated image corpus. This is\\nparticularly important in biomedical segmentation, since deformation used to'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2015-05-19T00:48:02+00:00', 'author': 'Olaf Ronneberger (ronneber@informatik.uni-freiburg.de), Philipp Fischer, Thomas Brox', 'keywords': '', 'moddate': '2015-05-19T00:48:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': 'U-Net: Convolutional Networks for Biomedical Image Segmentation', 'trapped': '/False', 'source': 'Unet for Biomedical Segmentation.pdf', 'total_pages': 8, 'page': 2, 'page_label': '3'}, page_content='the need to see these transformations in the annotated image corpus. This is\\nparticularly important in biomedical segmentation, since deformation used to\\nbe the most common variation in tissue and realistic deformations can be simu-\\nlated eﬃciently. The value of data augmentation for learning invariance has been\\nshown in Dosovitskiy et al. [2] in the scope of unsupervised feature learning.\\nAnother challenge in many cell segmentation tasks is the separation of touch-\\ning objects of the same class; see Figure 3. To this end, we propose the use of\\na weighted loss, where the separating background labels between touching cells\\nobtain a large weight in the loss function.\\nThe resulting network is applicable to various biomedical segmentation prob-\\nlems. In this paper, we show results on the segmentation of neuronal structures\\nin EM stacks (an ongoing competition started at ISBI 2012), where we out-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2015-05-19T00:48:02+00:00', 'author': 'Olaf Ronneberger (ronneber@informatik.uni-freiburg.de), Philipp Fischer, Thomas Brox', 'keywords': '', 'moddate': '2015-05-19T00:48:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': 'U-Net: Convolutional Networks for Biomedical Image Segmentation', 'trapped': '/False', 'source': 'Unet for Biomedical Segmentation.pdf', 'total_pages': 8, 'page': 3, 'page_label': '4'}, page_content='4\\nperformed the network of Ciresan et al. [1]. Furthermore, we show results for\\ncell segmentation in light microscopy images from the ISBI cell tracking chal-\\nlenge 2015. Here we won with a large margin on the two most challenging 2D\\ntransmitted light datasets.\\n2 Network Architecture\\nThe network architecture is illustrated in Figure 1. It consists of a contracting\\npath (left side) and an expansive path (right side). The contracting path follows\\nthe typical architecture of a convolutional network. It consists of the repeated\\napplication of two 3x3 convolutions (unpadded convolutions), each followed by\\na rectiﬁed linear unit (ReLU) and a 2x2 max pooling operation with stride 2\\nfor downsampling. At each downsampling step we double the number of feature\\nchannels. Every step in the expansive path consists of an upsampling of the\\nfeature map followed by a 2x2 convolution (“up-convolution”) that halves the\\nnumber of feature channels, a concatenation with the correspondingly cropped'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2015-05-19T00:48:02+00:00', 'author': 'Olaf Ronneberger (ronneber@informatik.uni-freiburg.de), Philipp Fischer, Thomas Brox', 'keywords': '', 'moddate': '2015-05-19T00:48:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': 'U-Net: Convolutional Networks for Biomedical Image Segmentation', 'trapped': '/False', 'source': 'Unet for Biomedical Segmentation.pdf', 'total_pages': 8, 'page': 3, 'page_label': '4'}, page_content='feature map followed by a 2x2 convolution (“up-convolution”) that halves the\\nnumber of feature channels, a concatenation with the correspondingly cropped\\nfeature map from the contracting path, and two 3x3 convolutions, each fol-\\nlowed by a ReLU. The cropping is necessary due to the loss of border pixels in\\nevery convolution. At the ﬁnal layer a 1x1 convolution is used to map each 64-\\ncomponent feature vector to the desired number of classes. In total the network\\nhas 23 convolutional layers.\\nTo allow a seamless tiling of the output segmentation map (see Figure 2), it\\nis important to select the input tile size such that all 2x2 max-pooling operations\\nare applied to a layer with an even x- and y-size.\\n3 Training\\nThe input images and their corresponding segmentation maps are used to train\\nthe network with the stochastic gradient descent implementation of Caﬀe [6].\\nDue to the unpadded convolutions, the output image is smaller than the input'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2015-05-19T00:48:02+00:00', 'author': 'Olaf Ronneberger (ronneber@informatik.uni-freiburg.de), Philipp Fischer, Thomas Brox', 'keywords': '', 'moddate': '2015-05-19T00:48:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': 'U-Net: Convolutional Networks for Biomedical Image Segmentation', 'trapped': '/False', 'source': 'Unet for Biomedical Segmentation.pdf', 'total_pages': 8, 'page': 3, 'page_label': '4'}, page_content='the network with the stochastic gradient descent implementation of Caﬀe [6].\\nDue to the unpadded convolutions, the output image is smaller than the input\\nby a constant border width. To minimize the overhead and make maximum use\\nof the GPU memory, we favor large input tiles over a large batch size and hence\\nreduce the batch to a single image. Accordingly we use a high momentum (0.99)\\nsuch that a large number of the previously seen training samples determine the\\nupdate in the current optimization step.\\nThe energy function is computed by a pixel-wise soft-max over the ﬁnal\\nfeature map combined with the cross entropy loss function. The soft-max is\\ndeﬁned as pk(x) = exp( ak(x))/\\n(∑K\\nk′=1 exp(ak′ (x))\\n)\\nwhere ak(x) denotes the\\nactivation in feature channel k at the pixel position x ∈Ω with Ω ⊂Z2. K\\nis the number of classes and pk(x) is the approximated maximum-function. I.e.\\npk(x) ≈1 for the k that has the maximum activation ak(x) and pk(x) ≈0 for'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2015-05-19T00:48:02+00:00', 'author': 'Olaf Ronneberger (ronneber@informatik.uni-freiburg.de), Philipp Fischer, Thomas Brox', 'keywords': '', 'moddate': '2015-05-19T00:48:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': 'U-Net: Convolutional Networks for Biomedical Image Segmentation', 'trapped': '/False', 'source': 'Unet for Biomedical Segmentation.pdf', 'total_pages': 8, 'page': 3, 'page_label': '4'}, page_content='is the number of classes and pk(x) is the approximated maximum-function. I.e.\\npk(x) ≈1 for the k that has the maximum activation ak(x) and pk(x) ≈0 for\\nall other k. The cross entropy then penalizes at each position the deviation of\\npℓ(x)(x) from 1 using\\nE =\\n∑\\nx∈Ω\\nw(x) log(pℓ(x)(x)) (1)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2015-05-19T00:48:02+00:00', 'author': 'Olaf Ronneberger (ronneber@informatik.uni-freiburg.de), Philipp Fischer, Thomas Brox', 'keywords': '', 'moddate': '2015-05-19T00:48:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': 'U-Net: Convolutional Networks for Biomedical Image Segmentation', 'trapped': '/False', 'source': 'Unet for Biomedical Segmentation.pdf', 'total_pages': 8, 'page': 4, 'page_label': '5'}, page_content='5\\na\\n b\\n c\\n d\\nFig. 3.HeLa cells on glass recorded with DIC (diﬀerential interference contrast) mi-\\ncroscopy. (a) raw image. ( b) overlay with ground truth segmentation. Diﬀerent colors\\nindicate diﬀerent instances of the HeLa cells. (c) generated segmentation mask (white:\\nforeground, black: background). ( d) map with a pixel-wise loss weight to force the\\nnetwork to learn the border pixels.\\nwhere ℓ : Ω →{1,...,K }is the true label of each pixel and w : Ω →R is\\na weight map that we introduced to give some pixels more importance in the\\ntraining.\\nWe pre-compute the weight map for each ground truth segmentation to com-\\npensate the diﬀerent frequency of pixels from a certain class in the training\\ndata set, and to force the network to learn the small separation borders that we\\nintroduce between touching cells (See Figure 3c and d).\\nThe separation border is computed using morphological operations. The\\nweight map is then computed as\\nw(x) = wc(x) + w0 ·exp\\n(\\n−(d1(x) + d2(x))2\\n2σ2\\n)\\n(2)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2015-05-19T00:48:02+00:00', 'author': 'Olaf Ronneberger (ronneber@informatik.uni-freiburg.de), Philipp Fischer, Thomas Brox', 'keywords': '', 'moddate': '2015-05-19T00:48:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': 'U-Net: Convolutional Networks for Biomedical Image Segmentation', 'trapped': '/False', 'source': 'Unet for Biomedical Segmentation.pdf', 'total_pages': 8, 'page': 4, 'page_label': '5'}, page_content='The separation border is computed using morphological operations. The\\nweight map is then computed as\\nw(x) = wc(x) + w0 ·exp\\n(\\n−(d1(x) + d2(x))2\\n2σ2\\n)\\n(2)\\nwhere wc : Ω →R is the weight map to balance the class frequencies,d1 : Ω →R\\ndenotes the distance to the border of the nearest cell andd2 : Ω →R the distance\\nto the border of the second nearest cell. In our experiments we set w0 = 10 and\\nσ≈5 pixels.\\nIn deep networks with many convolutional layers and diﬀerent paths through\\nthe network, a good initialization of the weights is extremely important. Oth-\\nerwise, parts of the network might give excessive activations, while other parts\\nnever contribute. Ideally the initial weights should be adapted such that each\\nfeature map in the network has approximately unit variance. For a network with\\nour architecture (alternating convolution and ReLU layers) this can be achieved\\nby drawing the initial weights from a Gaussian distribution with a standard\\ndeviation of\\n√'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2015-05-19T00:48:02+00:00', 'author': 'Olaf Ronneberger (ronneber@informatik.uni-freiburg.de), Philipp Fischer, Thomas Brox', 'keywords': '', 'moddate': '2015-05-19T00:48:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': 'U-Net: Convolutional Networks for Biomedical Image Segmentation', 'trapped': '/False', 'source': 'Unet for Biomedical Segmentation.pdf', 'total_pages': 8, 'page': 4, 'page_label': '5'}, page_content='our architecture (alternating convolution and ReLU layers) this can be achieved\\nby drawing the initial weights from a Gaussian distribution with a standard\\ndeviation of\\n√\\n2/N, where N denotes the number of incoming nodes of one neu-\\nron [5]. E.g. for a 3x3 convolution and 64 feature channels in the previous layer\\nN = 9 ·64 = 576.\\n3.1 Data Augmentation\\nData augmentation is essential to teach the network the desired invariance and\\nrobustness properties, when only few training samples are available. In case of'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2015-05-19T00:48:02+00:00', 'author': 'Olaf Ronneberger (ronneber@informatik.uni-freiburg.de), Philipp Fischer, Thomas Brox', 'keywords': '', 'moddate': '2015-05-19T00:48:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': 'U-Net: Convolutional Networks for Biomedical Image Segmentation', 'trapped': '/False', 'source': 'Unet for Biomedical Segmentation.pdf', 'total_pages': 8, 'page': 5, 'page_label': '6'}, page_content='6\\nmicroscopical images we primarily need shift and rotation invariance as well as\\nrobustness to deformations and gray value variations. Especially random elas-\\ntic deformations of the training samples seem to be the key concept to train\\na segmentation network with very few annotated images. We generate smooth\\ndeformations using random displacement vectors on a coarse 3 by 3 grid. The\\ndisplacements are sampled from a Gaussian distribution with 10 pixels standard\\ndeviation. Per-pixel displacements are then computed using bicubic interpola-\\ntion. Drop-out layers at the end of the contracting path perform further implicit\\ndata augmentation.\\n4 Experiments\\nWe demonstrate the application of the u-net to three diﬀerent segmentation\\ntasks. The ﬁrst task is the segmentation of neuronal structures in electron mi-\\ncroscopic recordings. An example of the data set and our obtained segmentation\\nis displayed in Figure 2. We provide the full result as Supplementary Material.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2015-05-19T00:48:02+00:00', 'author': 'Olaf Ronneberger (ronneber@informatik.uni-freiburg.de), Philipp Fischer, Thomas Brox', 'keywords': '', 'moddate': '2015-05-19T00:48:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': 'U-Net: Convolutional Networks for Biomedical Image Segmentation', 'trapped': '/False', 'source': 'Unet for Biomedical Segmentation.pdf', 'total_pages': 8, 'page': 5, 'page_label': '6'}, page_content='croscopic recordings. An example of the data set and our obtained segmentation\\nis displayed in Figure 2. We provide the full result as Supplementary Material.\\nThe data set is provided by the EM segmentation challenge [14] that was started\\nat ISBI 2012 and is still open for new contributions. The training data is a set of\\n30 images (512x512 pixels) from serial section transmission electron microscopy\\nof the Drosophila ﬁrst instar larva ventral nerve cord (VNC). Each image comes\\nwith a corresponding fully annotated ground truth segmentation map for cells\\n(white) and membranes (black). The test set is publicly available, but its seg-\\nmentation maps are kept secret. An evaluation can be obtained by sending the\\npredicted membrane probability map to the organizers. The evaluation is done\\nby thresholding the map at 10 diﬀerent levels and computation of the “warping\\nerror”, the “Rand error” and the “pixel error” [14].'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.12', 'creator': 'LaTeX with hyperref package', 'creationdate': '2015-05-19T00:48:02+00:00', 'author': 'Olaf Ronneberger (ronneber@informatik.uni-freiburg.de), Philipp Fischer, Thomas Brox', 'keywords': '', 'moddate': '2015-05-19T00:48:02+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.1415926-2.3-1.40.12 (TeX Live 2011) kpathsea version 6.0.1', 'subject': '', 'title': 'U-Net: Convolutional Networks for Biomedical Image Segmentation', 'trapped': '/False', 'source': 'Unet for Biomedical Segmentation.pdf', 'total_pages': 8, 'page': 5, 'page_label': '6'}, page_content='by thresholding the map at 10 diﬀerent levels and computation of the “warping\\nerror”, the “Rand error” and the “pixel error” [14].\\nThe u-net (averaged over 7 rotated versions of the input data) achieves with-\\nout any further pre- or postprocessing a warping error of 0.0003529 (the new\\nbest score, see Table 1) and a rand-error of 0.0382.\\nThis is signiﬁcantly better than the sliding-window convolutional network\\nresult by Ciresan et al. [1], whose best submission had a warping error of 0.000420\\nand a rand error of 0.0504. In terms of rand error the only better performing\\nTable 1.Ranking on the EM segmentation challenge [14] (march 6th, 2015), sorted\\nby warping error.\\nRank Group name Warping Error Rand Error Pixel Error\\n** human values ** 0.000005 0.0021 0.0010\\n1. u-net 0.000353 0.0382 0.0611\\n2. DIVE-SCI 0.000355 0.0305 0.0584\\n3. IDSIA [1] 0.000420 0.0504 0.0613\\n4. DIVE 0.000430 0.0545 0.0582\\n...\\n10. IDSIA-SCI 0.000653 0.0189 0.1027')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chunking\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "rct = RecursiveCharacterTextSplitter(chunk_size=1000 , chunk_overlap=200)\n",
    "documents = rct.split_documents(pdf_document)\n",
    "documents[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39aae123",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Smit\\AppData\\Local\\Temp\\ipykernel_26164\\1377632279.py:9: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  db = FAISS.from_documents(documents[:30] , HuggingFaceEmbeddings(\n",
      "c:\\Users\\Smit\\Desktop\\DESKTOP\\6th sem\\Langchain\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# from langchain_community.embeddings import OpenAIEmbeddings\n",
    "# Storing chunks in vectordb Chroma , FAISS\n",
    "from langchain_community.vectorstores import Chroma , FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings , OllamaEmbeddings\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "\n",
    "db = FAISS.from_documents(documents[:30] , HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91197a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'volutional neural networks. In: NIPS. pp. 1106–1114 (2012)\\n8. LeCun, Y., Boser, B., Denker, J.S., Henderson, D., Howard, R.E., Hubbard, W.,\\nJackel, L.D.: Backpropagation applied to handwritten zip code recognition. Neural\\nComputation 1(4), 541–551 (1989)\\n9. Long, J., Shelhamer, E., Darrell, T.: Fully convolutional networks for semantic\\nsegmentation (2014), arXiv:1411.4038 [cs.CV]\\n10. Maska, M., (...), de Solorzano, C.O.: A benchmark for comparison of cell tracking\\nalgorithms. Bioinformatics 30, 1609–1617 (2014)\\n11. Seyedhosseini, M., Sajjadi, M., Tasdizen, T.: Image segmentation with cascaded\\nhierarchical models and logistic disjunctive normal networks. In: Computer Vision\\n(ICCV), 2013 IEEE International Conference on. pp. 2168–2175 (2013)\\n12. Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale\\nimage recognition (2014), arXiv:1409.1556 [cs.CV]\\n13. WWW: Web page of the cell tracking challenge, http://www.codesolorzano.com/'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is the name of the paper\"\n",
    "result = db.similarity_search(query)\n",
    "result[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa2400c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Smit\\AppData\\Local\\Temp\\ipykernel_26164\\1304961890.py:2: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(\n",
    "    model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo\",\n",
    "    openai_api_key=\"3dbf00d2e4776e119e094fcfd9287265613f31fa154990452da4f12eff98aca3\",\n",
    "    openai_api_base=\"https://api.together.xyz/v1\",\n",
    "    temperature = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d58b28a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Design ChatPrompt Template\n",
    "from multiprocessing import context\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the following question based only on the provided context. \n",
    "Think step by step before providing a detailed answer. \n",
    "I will tip you $1000 if the user finds the answer helpful. \n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "Question: {input}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fad0f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document chaining\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "document= create_stuff_documents_chain(llm , prompt , document_variable_name='context')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc3c2257",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Chain Introduction\n",
    "## Create Stuff Docment Chain\n",
    "\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "document_chain=create_stuff_documents_chain(llm,prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "499c5a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000028125CB5580>, search_kwargs={})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever=db.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b95fa68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "retrieval_chain=create_retrieval_chain(retriever,document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d16aab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=retrieval_chain.invoke({\"input\":\"The u-net (averaged over 7 rotated versions of the input data) achieves with out any further pre- or postprocessing a warping error of\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "914048bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The u-net (averaged over 7 rotated versions of the input data) achieves without any further pre- or postprocessing a warping error of 0.0003529 and a rand-error of 0.0382.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe4e37f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
